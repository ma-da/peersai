{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550836df-122d-4ec3-82bd-4d1f15935ade",
   "metadata": {},
   "source": [
    "# 1. Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cbaa3e-68ec-4a07-8028-aa185b76af50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T18:09:58.540800Z",
     "iopub.status.busy": "2025-08-14T18:09:58.540579Z",
     "iopub.status.idle": "2025-08-14T18:10:03.785014Z",
     "shell.execute_reply": "2025-08-14T18:10:03.784400Z",
     "shell.execute_reply.started": "2025-08-14T18:09:58.540784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b19f26b8044a2799b2f2b8f1da2d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/792 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8377e1518bd450087e4cb9902568059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "base_model = \"deepseek-ai/deepseek-llm-7b-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "print(\"Loaded tokenizer ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfadde31-c64d-4842-b6f8-2fa3ea7fb4f1",
   "metadata": {},
   "source": [
    "# 2. Load base model in 4-bit or 8-bit if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bdab36-acb0-46cd-9c81-d18bd5c761a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T18:14:42.109956Z",
     "iopub.status.busy": "2025-08-14T18:14:42.109695Z",
     "iopub.status.idle": "2025-08-14T18:15:04.849410Z",
     "shell.execute_reply": "2025-08-14T18:15:04.848854Z",
     "shell.execute_reply.started": "2025-08-14T18:14:42.109938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed303f9b1614cf2950a28a374181382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d37d90bba3147bdbc965c7c0f48b58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae860432224c4ef3a1438398ecff6a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base model ✅\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,  # Optional for lower memory use\n",
    ")\n",
    "\n",
    "print(\"Loaded base model ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf7b6f-d5ff-4ed9-96f0-d880580034b5",
   "metadata": {},
   "source": [
    "# 3. Load LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2565c0d7-1662-4ff5-98b1-a27dcc759a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T18:18:47.656547Z",
     "iopub.status.busy": "2025-08-14T18:18:47.656315Z",
     "iopub.status.idle": "2025-08-14T18:18:48.079512Z",
     "shell.execute_reply": "2025-08-14T18:18:48.078907Z",
     "shell.execute_reply.started": "2025-08-14T18:18:47.656528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LoRa adapter ✅\n"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(model, \"my_lora\")\n",
    "print(\"Loaded LoRa adapter ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b8087-cd6b-4a8e-8f00-db0197b269ee",
   "metadata": {},
   "source": [
    "# 4. Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae2b497-a2f6-4445-b7af-7cdfbc88d079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T18:18:53.684864Z",
     "iopub.status.busy": "2025-08-14T18:18:53.684638Z",
     "iopub.status.idle": "2025-08-14T18:19:03.817148Z",
     "shell.execute_reply": "2025-08-14T18:19:03.816771Z",
     "shell.execute_reply.started": "2025-08-14T18:18:53.684848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n",
      "/conda/envs/unsloth/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:457: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the concept of entropy in simple terms.\n",
      "Entropy is a measure of the disorder or randomness in a system. It is a property of a system that describes how much energy is available to do work. The higher the entropy of a system, the more disordered it is, and the less energy it has available to do work.\n",
      "The concept of entropy was first proposed by Ludwig Boltzmann in the late 19th century. He suggested that entropy is a measure of the disorder or randomness in a system. The idea was that if a system is in a state of high entropy, it is more likely to be in a state of low entropy.\n",
      "The concept of entropy has been used in many fields, including thermodynamics, statistical mechanics, and information theory. In thermodynamics, entropy is used to describe the state of a system. In statistical mechanics, entropy is used to describe the probability distribution of a system. In information theory, entropy is used to describe the amount of information in a system.\n",
      "The concept of entropy has been used to\n",
      "Finished inference ✅\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the concept of entropy in simple terms.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "print(\"Finished inference ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
